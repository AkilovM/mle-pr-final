{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1a26b5",
   "metadata": {},
   "source": [
    "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã, –ü–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "-\n",
    "\n",
    "Baseline: —á–∏—Å—Ç–∏–º, –∫–æ–¥–∏—Ä—É–µ–º, –Ω–æ—Ä–º–∏—Ä—É–µ–º, –æ–±—É—á–∞–µ–º, –æ—Ü–µ–Ω–∏–≤–∞–µ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae739dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5897/2181999733.py:8: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dataset/train_ver2.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pickle\n",
    "#from category_encoders import CatBoostEncoder\n",
    "\n",
    "df = pd.read_csv('dataset/train_ver2.csv')\n",
    "df = df.drop(['tipodom'], axis=1)\n",
    "df_last_month = df[df['fecha_dato'] == \"2016-05-28\"]\n",
    "products = [x for x in df.columns if '_ult1' in x]\n",
    "\n",
    "def baseline_data_transform(df: pd.DataFrame, keep_user_ids=False):\n",
    "    \n",
    "    def remove_outliers(data: pd.DataFrame, outliers_columns: list):\n",
    "        num_cols = outliers_columns\n",
    "        threshold = 1.5\n",
    "        #potential_outliers = pd.DataFrame()\n",
    "\n",
    "        for col in num_cols:\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            margin = threshold * IQR\n",
    "            lower = Q1 - margin\n",
    "            upper = Q3 + margin\n",
    "            #potential_outliers[col] = ~data[col].between(lower, upper)\n",
    "            data = data[data[col].between(lower, upper)]\n",
    "        #return potential_outliers\n",
    "        return data\n",
    "\n",
    "    # –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü\n",
    "    df = df[df['fecha_dato'] == \"2016-05-28\"]\n",
    "\n",
    "    # —É–¥–∞–ª–∏—Ç—å —Å—Ç–æ–ª–±—Ü—ã\n",
    "    if keep_user_ids:\n",
    "        df = df.drop(['fecha_dato', 'ult_fec_cli_1t', 'conyuemp'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['fecha_dato', 'ncodpers', 'ult_fec_cli_1t', 'conyuemp'], axis=1)\n",
    "\n",
    "    # —É–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ c –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "    for col in df.columns.to_list():\n",
    "        if col not in ['renta']:\n",
    "            df = df[df[col].notna()]\n",
    "    \n",
    "    # –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –≤ —Ä–µ–Ω—Ç–µ –Ω—É–ª—è–º–∏\n",
    "    df['renta'] = df['renta'].fillna(0.0)\n",
    "\n",
    "    # age —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤ int, –ø–æ—á–∏—Å—Ç–∏—Ç—å –æ—Ç ' NA'\n",
    "    #TODO\n",
    "    df['age'] = df['age'].astype(int)\n",
    "\n",
    "    # fecha_alta –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤ int —á–∏—Å–ª–æ —Å–µ–∫—É–Ω–¥ —Å –Ω–∞—á–∞–ª–∞ —ç–ø–æ—Ö–∏\n",
    "    df['fecha_alta'] = pd.to_datetime(df['fecha_alta']).astype(int) / 10**9\n",
    "    \n",
    "    # antiguedad —Å—Ç—Ä–æ–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ int, –∏ –ø–æ—á–∏—Å—Ç–∏—Ç—å –æ—Ç –∑–Ω–∞—á–µ–Ω–∏–π —Ç–∏–ø–∞ '     NA', -999999.\n",
    "    #TODO\n",
    "    df = df[~df['antiguedad'] < 0]\n",
    "    df['antiguedad'] = df['antiguedad'].astype(int)\n",
    "\n",
    "    # indrel_1mes –Ω–∞–º–µ—à–∞–Ω—ã —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã, –Ω–∞–¥–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ–¥–Ω–æ–º—É —Ç–∏–ø—É 2.0 '2.0' '2' –∏—Ç–ø\n",
    "    #TODO\n",
    "    # —Ä–µ—à–∏–ª –≤ baseline —É–¥–∞–ª–∏—Ç—å —Å—Ç–æ–ª–±–µ—Ü\n",
    "    df = df.drop(['indrel_1mes'], axis=1)\n",
    "\n",
    "    # —É–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–æ—Å—ã\n",
    "    df = remove_outliers(df, ['age', 'renta', 'fecha_alta'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = baseline_data_transform(df_last_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6f682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    data.drop(products, axis=1),\n",
    "    data[products],\n",
    "    #stratify=data[products],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "categ_binary_vals = ['sexo', 'ind_nuevo', 'indrel', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente']\n",
    "categ_vals = ['ind_empleado', 'pais_residencia', 'tiprel_1mes', 'canal_entrada', 'cod_prov', 'nomprov', 'segmento'] # indrel_1mes\n",
    "numeric_vals = ['age', 'fecha_alta', 'antiguedad', 'renta']\n",
    "\n",
    "# –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ—à–∏–ª –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ –ø—Ä–∏–∑–Ω–∞–∫ renta —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —É—Ç–µ—á–∫–∏\n",
    "def encode_cat_via_renta(df: pd.DataFrame):\n",
    "    global_mean = df['renta'].mean()\n",
    "    alpha = 100  # –ß–µ–º –±–æ–ª—å—à–µ alpha, —Ç–µ–º —Å–∏–ª—å–Ω–µ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∫ global_mean\n",
    "    for cat in categ_vals:\n",
    "        # –§–æ—Ä–º—É–ª–∞: (mean_in_category * n_samples + global_mean * alpha) / (n_samples + alpha)\n",
    "        category_stats = df.groupby(cat)['renta'].agg(['mean', 'count'])\n",
    "        encoded_values = (\n",
    "            (category_stats['mean'] * category_stats['count'] + global_mean * alpha) / \n",
    "            (category_stats['count'] + alpha)\n",
    "        )\n",
    "        # –ó–∞–º–µ–Ω—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ\n",
    "        df[cat] = df[cat].map(encoded_values)\n",
    "    scaler = StandardScaler()\n",
    "    # –Ω–æ—Ä–º–∏—Ä—É–µ–º\n",
    "    df[categ_vals] = scaler.fit_transform(df[categ_vals])\n",
    "    return df\n",
    "\n",
    "X_tr = encode_cat_via_renta(X_tr)\n",
    "X_val = encode_cat_via_renta(X_val)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('binary', OneHotEncoder(drop='if_binary'), categ_binary_vals),\n",
    "        #('cat', ?, categ_vals),\n",
    "        ('num', StandardScaler(), numeric_vals),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_tr_transformed = preprocessor.fit_transform(X_tr, y_tr)\n",
    "X_val_transformed = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09715bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   23.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   20.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   19.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   23.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.78      0.81      0.79    132622\n",
      "           3       0.00      0.00      0.00        71\n",
      "           4       0.42      0.12      0.18     17118\n",
      "           5       0.94      0.92      0.93      1784\n",
      "           6       0.51      0.26      0.34      1858\n",
      "           7       0.55      0.35      0.43     22299\n",
      "           8       0.51      0.16      0.24      7582\n",
      "           9       0.00      0.00      0.00        70\n",
      "          10       0.00      0.00      0.00       242\n",
      "          11       0.55      0.27      0.37      7327\n",
      "          12       0.55      0.24      0.34     17592\n",
      "          13       0.34      0.03      0.05      3341\n",
      "          14       0.47      0.01      0.01      1055\n",
      "          15       0.31      0.01      0.02      1638\n",
      "          16       0.75      0.01      0.03       454\n",
      "          17       0.33      0.04      0.06     10351\n",
      "          18       0.30      0.03      0.06      8013\n",
      "          19       0.30      0.03      0.06      4776\n",
      "          20       0.00      0.00      0.00       617\n",
      "          21       0.40      0.08      0.13     11360\n",
      "          22       0.40      0.08      0.13     12374\n",
      "          23       0.48      0.28      0.36     26369\n",
      "\n",
      "   micro avg       0.70      0.47      0.56    288940\n",
      "   macro avg       0.37      0.16      0.19    288940\n",
      "weighted avg       0.61      0.47      0.50    288940\n",
      " samples avg       0.51      0.46      0.47    288940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = MultiOutputClassifier(RandomForestClassifier(\n",
    "    n_estimators=50,  # –£–º–µ–Ω—å—à–∏—Ç–µ, –µ—Å–ª–∏ –¥–æ–ª–≥–æ (–Ω–∞—á–Ω–∏—Ç–µ —Å 50)\n",
    "    verbose=1,         # –í—ã–≤–æ–¥ –ª–æ–≥–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "    n_jobs=-1          # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ —è–¥—Ä–∞ CPU\n",
    "))\n",
    "model.fit(X_tr_transformed, y_tr)\n",
    "\n",
    "predictions = model.predict(X_val_transformed)\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2eb83",
   "metadata": {},
   "source": [
    "–°–º–æ—Ç—Ä–∏–º f1-score:\n",
    "- macro avg = 0.19 - –º–æ–¥–µ–ª—å –ø–ª–æ—Ö–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ–º –∫–ª–∞—Å—Å–æ–≤.\n",
    "- weighted avg = 0.50 - —Å —É—á–µ—Ç–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ –º–æ–¥–µ–ª—å —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –ª—É—á—à–µ –Ω–∞ –∫–ª–∞—Å—Å–∞—Ö –ø–æ–∫—Ä—É–ø–Ω–µ–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51298a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "with open('model_baseline_RandomForestClassification.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d22f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º\n",
    "with open('model_baseline_RandomForestClassification.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27501c",
   "metadata": {},
   "source": [
    "–ó–∞–ª–æ–≥–∏—Ä—É–µ–º baseline –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113cc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run baseline at: http://127.0.0.1:5000/#/experiments/1/runs/e8019caba6c544488ecbb8c8aa68584b\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_registry_uri(mlflow_tracking_uri)\n",
    "\n",
    "EXPERIMENT_NAME = \"spain_bank\"\n",
    "RUN_NAME = \"baseline\"\n",
    "\n",
    "metrics = {'f1-score macro avg': 0.19,\n",
    "           'f1-score weighted avg': 0.50}\n",
    "signature = mlflow.models.infer_signature(X_val_transformed, predictions)\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "if not experiment_id:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME) \n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # model_info = mlflow.sklearn.log_model(\n",
    "    #     sk_model=model, \n",
    "    #     artifact_path='models',\n",
    "    #     await_registration_for=60,\n",
    "    #     signature=signature,\n",
    "    #     registered_model_name='model_spain_bank_baseline',\n",
    "    #     code_paths=['experiments.ipynb'],\n",
    "    #     pip_requirements='requirements.txt'\n",
    "    # )\n",
    "    \n",
    "    # –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –≤–æ—Ä–∫–µ—Ä –≤–∏—Å–Ω–µ—Ç –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏.\n",
    "    # —Å–æ—Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫–∏, –∞ –º–æ–¥–µ–ª—å –µ—Å–ª–∏ —á—Ç–æ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Ñ–∞–π–ª–æ–º .pkl\n",
    "    mlflow.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f2215",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –≤—ã—à–ª–∞ —Ä–∞–∑–º–µ—Ä–æ–º 4.7 –ì–ë, –∏ –æ–¥–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–æ–ª–≥–æ.\n",
    "\n",
    "–û–±—É—á–∏–º –¥—Ä—É–≥—É—é –ø–æ–ª–µ–≥—á–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ccaed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.74      0.82      0.78    132622\n",
      "           3       0.00      0.00      0.00        71\n",
      "           4       0.00      0.00      0.00     17118\n",
      "           5       0.86      0.87      0.87      1784\n",
      "           6       0.29      0.00      0.01      1858\n",
      "           7       0.37      0.16      0.22     22299\n",
      "           8       0.00      0.00      0.00      7582\n",
      "           9       0.00      0.00      0.00        70\n",
      "          10       0.00      0.00      0.00       242\n",
      "          11       0.59      0.23      0.33      7327\n",
      "          12       0.53      0.19      0.27     17592\n",
      "          13       1.00      0.00      0.00      3341\n",
      "          14       0.00      0.00      0.00      1055\n",
      "          15       0.00      0.00      0.00      1638\n",
      "          16       0.00      0.00      0.00       454\n",
      "          17       0.47      0.00      0.00     10351\n",
      "          18       0.64      0.00      0.00      8013\n",
      "          19       0.48      0.00      0.01      4776\n",
      "          20       0.00      0.00      0.00       617\n",
      "          21       0.00      0.00      0.00     11360\n",
      "          22       0.00      0.00      0.00     12374\n",
      "          23       0.62      0.04      0.08     26369\n",
      "\n",
      "   micro avg       0.71      0.42      0.52    288940\n",
      "   macro avg       0.27      0.10      0.11    288940\n",
      "weighted avg       0.53      0.42      0.41    288940\n",
      " samples avg       0.52      0.44      0.46    288940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = MultiOutputClassifier(\n",
    "    LogisticRegression(max_iter=1000, solver=\"lbfgs\", n_jobs=-1),\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_tr_transformed, y_tr)\n",
    "\n",
    "predictions = model.predict(X_val_transformed)\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "with open('model_baseline_LogReg.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º\n",
    "with open('model_baseline_LogReg.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4572f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 12:30:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Successfully registered model 'model_spain_bank_baseline_logreg'.\n",
      "2025/07/28 12:30:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 60 seconds for model version to finish creation. Model name: model_spain_bank_baseline_logreg, version 1\n",
      "Created version '1' of model 'model_spain_bank_baseline_logreg'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run baseline_logreg at: http://127.0.0.1:5000/#/experiments/1/runs/aa24b8c063c3471eb1c0eaeef2dde3b0\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_registry_uri(mlflow_tracking_uri)\n",
    "\n",
    "EXPERIMENT_NAME = \"spain_bank\"\n",
    "RUN_NAME = \"baseline_logreg\"\n",
    "\n",
    "metrics = {'f1-score macro avg': 0.11,\n",
    "           'f1-score weighted avg': 0.41}\n",
    "signature = mlflow.models.infer_signature(X_val_transformed, predictions)\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "if not experiment_id:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME) \n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model, \n",
    "        artifact_path='models',\n",
    "        await_registration_for=60,\n",
    "        signature=signature,\n",
    "        registered_model_name='model_spain_bank_baseline_logreg',\n",
    "        code_paths=['experiments.ipynb'],\n",
    "        pip_requirements='requirements.txt'\n",
    "    )\n",
    "\n",
    "    mlflow.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba97c0",
   "metadata": {},
   "source": [
    "–ö–∞—á–µ—Å—Ç–≤–æ —á—É—Ç—å —Ö—É–∂–µ, –Ω–æ –º–æ–¥–µ–ª—å –≥–æ—Ä–∞–∑–¥–æ –ª–µ–≥—á–µ –∏ –±—ã—Å—Ç—Ä–µ–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c86942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "def pack_prod_obj():\n",
    "    products_spanish_to_ru_dict = {\n",
    "        'ind_ahor_fin_ult1':\t'–°–±–µ—Ä–µ–≥–∞—Ç–µ–ª—å–Ω—ã–π —Å—á—ë—Ç',\n",
    "        'ind_aval_fin_ult1':\t'–ë–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è',\n",
    "        'ind_cco_fin_ult1':\t'–¢–µ–∫—É—â–∏–µ —Å—á–µ—Ç–∞',\n",
    "        'ind_cder_fin_ult1':\t'–î–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω—ã–π —Å—á—ë—Ç',\n",
    "        'ind_cno_fin_ult1':\t'–ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç',\n",
    "        'ind_ctju_fin_ult1':\t'–î–µ—Ç—Å–∫–∏–π —Å—á—ë—Ç',\n",
    "        'ind_ctma_fin_ult1':\t'–û—Å–æ–±—ã–π —Å—á—ë—Ç 3',\n",
    "        'ind_ctop_fin_ult1':\t'–û—Å–æ–±—ã–π —Å—á—ë—Ç',\n",
    "        'ind_ctpp_fin_ult1':\t'–û—Å–æ–±—ã–π —Å—á—ë—Ç 2',\n",
    "        'ind_deco_fin_ult1':\t'–ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–π –¥–µ–ø–æ–∑–∏—Ç',\n",
    "        'ind_deme_fin_ult1':\t'–°—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω—ã–π –¥–µ–ø–æ–∑–∏—Ç',\n",
    "        'ind_dela_fin_ult1':\t'–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π –¥–µ–ø–æ–∑–∏—Ç',\n",
    "        'ind_ecue_fin_ult1':\t'–¶–∏—Ñ—Ä–æ–≤–æ–π —Å—á—ë—Ç',\n",
    "        'ind_fond_fin_ult1':\t'–î–µ–Ω–µ–∂–Ω—ã–π —Å—Ä–µ–¥—Å—Ç–≤–∞',\n",
    "        'ind_hip_fin_ult1':\t'–ò–ø–æ—Ç–µ–∫–∞',\n",
    "        'ind_plan_fin_ult1':\t'–ü–µ–Ω—Å–∏–æ–Ω–Ω—ã–π –ø–ª–∞–Ω',\n",
    "        'ind_pres_fin_ult1':\t'–ö—Ä–µ–¥–∏—Ç',\n",
    "        'ind_reca_fin_ult1':\t'–ù–∞–ª–æ–≥–æ–≤—ã–π —Å—á—ë—Ç',\n",
    "        'ind_tjcr_fin_ult1':\t'–ö—Ä–µ–¥–∏—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞',\n",
    "        'ind_valo_fin_ult1':\t'–¶–µ–Ω–Ω—ã–µ –±—É–º–∞–≥–∏',\n",
    "        'ind_viv_fin_ult1':\t'–î–æ–º–∞—à–Ω–∏–π —Å—á—ë—Ç',\n",
    "        'ind_nomina_ult1':\t'–ê–∫–∫–∞—É–Ω—Ç –¥–ª—è –≤—ã–ø–ª–∞—Ç—ã –∑–∞—Ä–ø–ª–∞—Ç—ã',\n",
    "        'ind_nom_pens_ult1':\t'–ê–∫–∫–∞—É–Ω—Ç –¥–ª—è –ø–µ–Ω—Å–∏–æ–Ω–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤',\n",
    "        'ind_recibo_ult1':\t'–î–µ–±–µ—Ç–æ–≤—ã–π –∞–∫–∫–∞—É–Ω—Ç',\n",
    "    }\n",
    "    data_for_user_ids = baseline_data_transform(df_last_month, keep_user_ids=True)\n",
    "    user_id_order = data_for_user_ids['ncodpers'].to_list()\n",
    "\n",
    "    # data.drop(products, axis=1),\n",
    "    # data[products],\n",
    "\n",
    "    X_prod = encode_cat_via_renta(data.drop(products, axis=1))\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "            ('binary', OneHotEncoder(drop='if_binary'), categ_binary_vals),\n",
    "            #('cat', ?, categ_vals),\n",
    "            ('num', StandardScaler(), numeric_vals),\n",
    "        ],\n",
    "        verbose_feature_names_out=False,\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_prod_transformed = preprocessor.fit_transform(X_prod, data[products])\n",
    "\n",
    "    prod_obj = {\n",
    "        'products_spanish_to_ru_dict': products_spanish_to_ru_dict,\n",
    "        'user_id_order': user_id_order,\n",
    "        'products': products,\n",
    "        'features': X_prod_transformed,\n",
    "    }\n",
    "    return prod_obj\n",
    "\n",
    "prod_obj = pack_prod_obj()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "with open('prod_obj.pkl', 'wb') as f:\n",
    "    pickle.dump(prod_obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb969378",
   "metadata": {},
   "source": [
    "Advanced\n",
    "-\n",
    "TODO\n",
    "\n",
    "–í—Ä–µ–º–µ–Ω–∏ –Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ—á—Ç–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å, –ø–æ—ç—Ç–æ–º—É –æ—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ–∫—É—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe3b2f",
   "metadata": {},
   "source": [
    "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã:\n",
    "- –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏—Ç—å —Ç–∞—Ä–≥–µ—Ç—ã (—Å–º. EDA)\n",
    "- –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ n-–≥–æ –º–µ—Å—è—Ü–∞ –ª–µ–∂–∞–ª–∏ —Å —Ç–∞—Ä–≥–µ—Ç–∞–º–∏ n+1-–≥–æ –º–µ—Å—è—Ü–∞;\n",
    "- —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫ - –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ–ª—è `renta` –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ n –º–µ—Å—è—Ü–µ–≤;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data):\n",
    "    feature_cols = data.columns.drop('customer_id').tolist()\n",
    "    is_duplicated_features = data.duplicated(subset=feature_cols, keep=False)\n",
    "    data = data[~is_duplicated_features].reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def fill_missing_values(data):\n",
    "\n",
    "    cols_with_nans = data.isnull().sum()\n",
    "    cols_with_nans = cols_with_nans[cols_with_nans > 0].index.drop('end_date')\n",
    "\n",
    "    for col in cols_with_nans:\n",
    "\n",
    "        if data[col].dtype in [float, int]:\n",
    "            fill_value = data[col].mean()\n",
    "        elif data[col].dtype == 'object':\n",
    "            fill_value = data[col].mode().iloc[0]\n",
    "\n",
    "        data[col] = data[col].fillna(fill_value)\n",
    "\n",
    "    return data\n",
    "\n",
    "def remove_outliers(data):\n",
    "    num_cols = data.select_dtypes(['float']).columns\n",
    "    threshold = 1.5\n",
    "    potential_outliers = pd.DataFrame()\n",
    "\n",
    "    for col in num_cols:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        margin = threshold * IQR\n",
    "        lower = Q1 - margin\n",
    "        upper = Q3 + margin\n",
    "        potential_outliers[col] = ~data[col].between(lower, upper)\n",
    "    return potential_outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
