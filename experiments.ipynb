{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1a26b5",
   "metadata": {},
   "source": [
    "Эксперименты, Пайплайн обработки данных, Построение модели\n",
    "-\n",
    "\n",
    "Baseline: чистим, кодируем, нормируем, обучаем, оцениваем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae739dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6440/2181999733.py:8: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dataset/train_ver2.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "#from category_encoders import CatBoostEncoder\n",
    "\n",
    "df = pd.read_csv('dataset/train_ver2.csv')\n",
    "df = df.drop(['tipodom'], axis=1)\n",
    "df_last_month = df[df['fecha_dato'] == \"2016-05-28\"]\n",
    "products = [x for x in df.columns if '_ult1' in x]\n",
    "\n",
    "def baseline_data_transform(df: pd.DataFrame):\n",
    "    \n",
    "    def remove_outliers(data: pd.DataFrame, outliers_columns: list):\n",
    "        num_cols = outliers_columns\n",
    "        threshold = 1.5\n",
    "        #potential_outliers = pd.DataFrame()\n",
    "\n",
    "        for col in num_cols:\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            margin = threshold * IQR\n",
    "            lower = Q1 - margin\n",
    "            upper = Q3 + margin\n",
    "            #potential_outliers[col] = ~data[col].between(lower, upper)\n",
    "            data = data[data[col].between(lower, upper)]\n",
    "        #return potential_outliers\n",
    "        return data\n",
    "\n",
    "    # берём только последний месяц\n",
    "    df = df[df['fecha_dato'] == \"2016-05-28\"]\n",
    "\n",
    "    # удалить столбцы\n",
    "    df = df.drop(['fecha_dato', 'ncodpers', 'ult_fec_cli_1t', 'conyuemp'], axis=1)\n",
    "\n",
    "    # удалить строки\n",
    "    for col in df.columns.to_list():\n",
    "        if col not in ['renta']:\n",
    "            df = df[df[col].notna()]\n",
    "    \n",
    "    # заполнить пропуски в ренте нулями\n",
    "    df['renta'] = df['renta'].fillna(0.0)\n",
    "\n",
    "    # age строки перевести в int, почистить от ' NA'\n",
    "    #TODO\n",
    "    df['age'] = df['age'].astype(int)\n",
    "\n",
    "    # fecha_alta перевести в int число секунд с начала эпохи\n",
    "    df['fecha_alta'] = pd.to_datetime(df['fecha_alta']).astype(int) / 10**9\n",
    "    \n",
    "    # antiguedad строки конвертировать в int, и почистить от значений типа '     NA', -999999.\n",
    "    #TODO\n",
    "    df = df[~df['antiguedad'] < 0]\n",
    "    df['antiguedad'] = df['antiguedad'].astype(int)\n",
    "\n",
    "    # indrel_1mes намешаны разные типы, надо привести к одному типу 2.0 '2.0' '2' итп\n",
    "    #TODO\n",
    "    # решил в baseline удалить столбец\n",
    "    df = df.drop(['indrel_1mes'], axis=1)\n",
    "\n",
    "    # убираем выбросы\n",
    "    df = remove_outliers(df, ['age', 'renta', 'fecha_alta'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = baseline_data_transform(df_last_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6f682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    data.drop(products, axis=1),\n",
    "    data[products],\n",
    "    #stratify=data[products],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "categ_binary_vals = ['sexo', 'ind_nuevo', 'indrel', 'indresi', 'indext', 'indfall', 'ind_actividad_cliente']\n",
    "categ_vals = ['ind_empleado', 'pais_residencia', 'tiprel_1mes', 'canal_entrada', 'cod_prov', 'nomprov', 'segmento'] # indrel_1mes\n",
    "numeric_vals = ['age', 'fecha_alta', 'antiguedad', 'renta']\n",
    "\n",
    "# категориальные признаки решил закодировать через признак renta чтобы не было утечки\n",
    "def encode_cat_via_renta(df: pd.DataFrame):\n",
    "    global_mean = df['renta'].mean()\n",
    "    alpha = 100  # Чем больше alpha, тем сильнее сглаживание к global_mean\n",
    "    for cat in categ_vals:\n",
    "        # Формула: (mean_in_category * n_samples + global_mean * alpha) / (n_samples + alpha)\n",
    "        category_stats = df.groupby(cat)['renta'].agg(['mean', 'count'])\n",
    "        encoded_values = (\n",
    "            (category_stats['mean'] * category_stats['count'] + global_mean * alpha) / \n",
    "            (category_stats['count'] + alpha)\n",
    "        )\n",
    "        # Заменяем категориальные значения на закодированные\n",
    "        df[cat] = df[cat].map(encoded_values)\n",
    "    scaler = StandardScaler()\n",
    "    # нормируем\n",
    "    df[categ_vals] = scaler.fit_transform(df[categ_vals])\n",
    "    return df\n",
    "\n",
    "X_tr = encode_cat_via_renta(X_tr)\n",
    "X_val = encode_cat_via_renta(X_val)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('binary', OneHotEncoder(drop='if_binary'), categ_binary_vals),\n",
    "        #('cat', ?, categ_vals),\n",
    "        ('num', StandardScaler(), numeric_vals),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_tr_transformed = preprocessor.fit_transform(X_tr, y_tr)\n",
    "X_val_transformed = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09715bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   23.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   20.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   19.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   23.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.78      0.81      0.79    132622\n",
      "           3       0.00      0.00      0.00        71\n",
      "           4       0.42      0.12      0.18     17118\n",
      "           5       0.94      0.92      0.93      1784\n",
      "           6       0.51      0.26      0.34      1858\n",
      "           7       0.55      0.35      0.43     22299\n",
      "           8       0.51      0.16      0.24      7582\n",
      "           9       0.00      0.00      0.00        70\n",
      "          10       0.00      0.00      0.00       242\n",
      "          11       0.55      0.27      0.37      7327\n",
      "          12       0.55      0.24      0.34     17592\n",
      "          13       0.34      0.03      0.05      3341\n",
      "          14       0.47      0.01      0.01      1055\n",
      "          15       0.31      0.01      0.02      1638\n",
      "          16       0.75      0.01      0.03       454\n",
      "          17       0.33      0.04      0.06     10351\n",
      "          18       0.30      0.03      0.06      8013\n",
      "          19       0.30      0.03      0.06      4776\n",
      "          20       0.00      0.00      0.00       617\n",
      "          21       0.40      0.08      0.13     11360\n",
      "          22       0.40      0.08      0.13     12374\n",
      "          23       0.48      0.28      0.36     26369\n",
      "\n",
      "   micro avg       0.70      0.47      0.56    288940\n",
      "   macro avg       0.37      0.16      0.19    288940\n",
      "weighted avg       0.61      0.47      0.50    288940\n",
      " samples avg       0.51      0.46      0.47    288940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mle-user/mle_projects/sprint-projects/mle-pr-final/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = MultiOutputClassifier(RandomForestClassifier(\n",
    "    n_estimators=50,  # Уменьшите, если долго (начните с 50)\n",
    "    verbose=1,         # Вывод лога обучения\n",
    "    n_jobs=-1          # Использовать все ядра CPU\n",
    "))\n",
    "model.fit(X_tr_transformed, y_tr)\n",
    "\n",
    "predictions = model.predict(X_val_transformed)\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2eb83",
   "metadata": {},
   "source": [
    "Смотрим f1-score:\n",
    "- macro avg = 0.19 - модель плохо справляется с большинством классов.\n",
    "- weighted avg = 0.50 - с учетом количества в каждом классе модель справляется лучше на классах покрупнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51298a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Сохраняем\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Загружаем\n",
    "# with open('model.pkl', 'rb') as f:\n",
    "#     model_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d22f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Загружаем\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb969378",
   "metadata": {},
   "source": [
    "Advanced\n",
    "-\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe3b2f",
   "metadata": {},
   "source": [
    "Эксперименты:\n",
    "- переделать датасет так, чтобы признаки n-го месяца лежали с таргетами n+1-го месяца;\n",
    "- сгенерировать признак - динамика поля `renta` за последние n месяцев;\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data):\n",
    "    feature_cols = data.columns.drop('customer_id').tolist()\n",
    "    is_duplicated_features = data.duplicated(subset=feature_cols, keep=False)\n",
    "    data = data[~is_duplicated_features].reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def fill_missing_values(data):\n",
    "\n",
    "    cols_with_nans = data.isnull().sum()\n",
    "    cols_with_nans = cols_with_nans[cols_with_nans > 0].index.drop('end_date')\n",
    "\n",
    "    for col in cols_with_nans:\n",
    "\n",
    "        if data[col].dtype in [float, int]:\n",
    "            fill_value = data[col].mean()\n",
    "        elif data[col].dtype == 'object':\n",
    "            fill_value = data[col].mode().iloc[0]\n",
    "\n",
    "        data[col] = data[col].fillna(fill_value)\n",
    "\n",
    "    return data\n",
    "\n",
    "def remove_outliers(data):\n",
    "    num_cols = data.select_dtypes(['float']).columns\n",
    "    threshold = 1.5\n",
    "    potential_outliers = pd.DataFrame()\n",
    "\n",
    "    for col in num_cols:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        margin = threshold * IQR\n",
    "        lower = Q1 - margin\n",
    "        upper = Q3 + margin\n",
    "        potential_outliers[col] = ~data[col].between(lower, upper)\n",
    "    return potential_outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
